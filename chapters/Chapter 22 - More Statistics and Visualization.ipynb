{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This material is copied (possibily with some modifications) from the [Python for Text-Analysis course](https://github.com/cltl/python-for-text-analysis/tree/master/Chapters)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 19 - More Statistics and Visualization\n",
    "\n",
    "At this point in the course, you have had some experience in getting and processing data, and exporting your results in a useful format. But after that stage, you also need to be able to *analyze* and *communicate* your results. Programming-wise, this is relatively easy. There are tons of great modules out there for doing statistics and making pretty graphs. The hard part is finding out what is the best way to communicate your findings.\n",
    "\n",
    "**At the end of this chapter, you will be able to:**\n",
    "- Have an overview of different kinds of visualizations and their purpose\n",
    "- Communicate your results using visualizations, that is:\n",
    "    - Make line plots.\n",
    "    - Make bar and column charts.\n",
    "    - Modify your plot to improve its visual appearance\n",
    "- Compute two correlation metrics\n",
    "- Perform exploratory data analysis, using both visual and statistical means.\n",
    "\n",
    "\n",
    "**This requires that you already have (some) knowledge about:**\n",
    "- Loading and manipulating data.\n",
    "\n",
    "**If you want to learn more about these topics, you might find the following links useful:**\n",
    "- Visualization blog: http://gravyanecdote.com/ \n",
    "- List of visualization blogs: https://flowingdata.com/2012/04/27/data-and-visualization-blogs-worth-following/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to visualization\n",
    "\n",
    "\n",
    "### 1.1. What kind of visualization to choose\n",
    "\n",
    "Visualization has two purposes: *aesthethics* and *informativeness*. We want to optimize for both. Luckily, they are somewhat independent, so that should work. Whether something will be a good visualization will be determined by: whether the creator makes the right **choices**, in the given **context**, for the given **audience** and **purpose**.\n",
    "\n",
    "The following chart was made by ([Abela, 2006](http://extremepresentation.typepad.com/blog/2006/09/choosing_a_good.html)). It provides a first intuition on what kind of visualization to choose for your data. He also asks exactly the right question: **What do you want to show?** It is essential for any piece of communication to first consider: what is my main point? And after creating a visualization, to ask yourself: does this visualization indeed communicate what I want to communicate? (Ideally, also ask others: what kind of message am I conveying here?)\n",
    "\n",
    "![chart_chooser](./images/chart_chooser.jpg)\n",
    "\n",
    "It's also apt to call this a 'Thought-starter'. Not all visualizations in this diagram are frequently used; but also there are many great kinds of visualizations that aren't in this diagram. To get some more inspiration, check out the example galleries for these libraries:\n",
    "\n",
    "* [D3.js](https://d3js.org/)\n",
    "* [Seaborn](https://seaborn.github.io/examples/index.html)\n",
    "* [Bokeh](http://bokeh.pydata.org/en/latest/docs/gallery.html)\n",
    "* [Pandas](http://pandas.pydata.org/pandas-docs/version/0.18.1/visualization.html)\n",
    "* [Matplotlib](http://matplotlib.org/gallery.html)\n",
    "* [Vis.js](http://visjs.org/index.html)\n",
    "\n",
    "But before you get carried away, do realize that **sometimes all you need is a good table**. Tables are visualizations, too! For a good guide on how to make tables, read the first three pages of [the LaTeX booktabs package documentation](http://ctan.cs.uu.nl/macros/latex/contrib/booktabs/booktabs.pdf). Also see [this guide](https://www.behance.net/gallery/Designing-Effective-Data-Tables/885004) with some practical tips.\n",
    "\n",
    "### 1.2. What kind of visualizations *not* to choose\n",
    "\n",
    "As a warm-up exercise, take some time to browse [wtf-viz](http://viz.wtf/). For each of the examples, think about the following questions:\n",
    "\n",
    "1. What is the author trying to convey here?\n",
    "2. How did they try to achieve this?\n",
    "3. What went wrong?\n",
    "4. How could the visualization be improved? Or can you think of a better way to visualize this data?\n",
    "5. What is the take-home message here for you?\n",
    "\n",
    "For in-depth critiques of visualizations, see [Graphic Violence](https://graphicviolence.wordpress.com/). [Here](http://hanswisbrun.nl/tag/lieggrafiek/)'s a page in Dutch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualization in Python\n",
    "\n",
    "### 2.1. A little history\n",
    "\n",
    "As you've seen in the [State of the tools](https://www.youtube.com/watch?v=5GlNDD7qbP4) video, `Matplotlib` is one of the core libraries for visualization. It's feature-rich, and there are many tutorials and examples showing you how to make nice graphs. It's also fairly clunky, however, and the default settings don't make for very nice graphs. But because `Matplotlib` is so powerful, no one wanted to throw the library away. So now there are several modules that provide wrapper functions around `Matplotlib`, so as to make it easier to use and produce nice-looking graphs.\n",
    "\n",
    "* `Seaborn` is a visualization library that adds a lot of functionality and good-looking defaults to Matplotlib.\n",
    "* `Pandas` is a data analysis library that provides plotting methods for its `dataframe` objects.\n",
    "\n",
    "Behind the scenes, it's all still Matplotlib. So if you use any of these libraries to create a graph, and you want to customize the graph a little, it's usually a good idea to go through the `Matplotlib` documentation. Meanwhile, the developers of `Matplotlib` are still improving the library. If you have 20 minutes to spare, watch [this video](https://www.youtube.com/watch?v=xAoljeRJ3lU) on the new default colormap that will be used in Matplotlib 2.0. It's a nice talk that highlights the importance of color theory in creating visualizations.\n",
    "\n",
    "With the web becoming more and more popular, there are now also several libraries in Python offering interactive visualizations using Javascript instead of Matplotlib. These are, among others:\n",
    "\n",
    "* [Bokeh](http://bokeh.pydata.org/en/latest/)\n",
    "* [NVD3](http://nvd3.org/)\n",
    "* [Lightning](http://lightning-viz.org/)\n",
    "* [MPLD3](http://mpld3.github.io/) (Also using Matplotlib)\n",
    "* [Plotly](https://plot.ly/)\n",
    "* [Vincent](https://vincent.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Getting started\n",
    "\n",
    "This section shows you how to make plots using Matplotlib and Seaborn.\n",
    "\n",
    "Run the cell below. This will load relevant packages to use visualizations inside the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is special Jupyter notebook syntax, enabling interactive plotting mode.\n",
    "# In this mode, all plots are shown inside the notebook!\n",
    "# If you are not using notebooks (e.g. in a standalone script), don't include this.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a simple command from another package, Seaborn, to make all Matplotlib plots look prettier!\n",
    "This import and the next command change the Matplotlib defaults for styling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Common plots\n",
    "\n",
    "**Example 1: Line plot** Let's create our first (line) plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [3,2,5,0,1]\n",
    "plt.plot(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went alright, you see a graph above this block. Try changing the numbers in the vals list to see how it affects the graph. Plotting is as simple as that!\n",
    "\n",
    "**Example 2: Column chart** Now, let's try plotting some collected data. Suppose we did a survey to ask people for their favorite pizza. We store the result in a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {\n",
    "    'Calzone': 63,\n",
    "    'Quattro Stagioni': 43,\n",
    "    'Hawaii': 40,\n",
    "    'Pepperoni': 58,\n",
    "    'Diavolo': 63,\n",
    "    'Frutti di Mare': 32,\n",
    "    'Margarita': 55,\n",
    "    'Quattro Formaggi': 10,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loop processes the dictionary into a format that's easy to send to matplotlib - a list of pizza names (for the labels on the bars) and a list of vote counts (for the actual graph.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "votes = []\n",
    "# Split the dictionary of names->votes into two lists, one holding names and the other holding vote counts\n",
    "for pizza in counts:\n",
    "    names.append(pizza)\n",
    "    votes.append(counts[pizza])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a range of indexes for the X values in the graph, one entry for each entry in the \"counts\" dictionary (ie len(counts)), numbered 0,1,2,3,etc. This will spread out the graph bars evenly across the X axis on the plot.\n",
    "\n",
    "*np.arange* is a NumPy function like the range() function in Python, only the result it produces is a \"NumPy array\". We'll see why this is useful in a second.\n",
    "\n",
    "*plt.bar()* creates a column graph, using the \"x\" values as the X axis positions and the values in the votes array (ie the vote counts) as the height of each bar. Finally, we add the labels, rotated with a certain angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.arange(len(counts))\n",
    "print(x)\n",
    "plt.bar(x, votes)\n",
    "plt.xticks(x, names, rotation=60)\n",
    "plt.yticks(votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Can you add a Y-axis label to the chart? Have a look [here](https://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.ylabel) for pointers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3: Bar chart** Both the Bar and the Column charts display data using rectangular bars where the length of the bar is proportional to the data value. Both are used to compare two or more values. However, their difference lies in their orientation. A Bar chart is oriented horizontally whereas the Column chart is oriented vertically. See [this blog](https://www.fusioncharts.com/blog/bar-charts-or-column-charts/) for a discussion on when to use bar and when to use column charts.\n",
    "\n",
    "Here is how to plot a bar chart (yes, very similar to a column chart):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(counts))\n",
    "print(x)\n",
    "plt.barh(x, votes)\n",
    "plt.yticks(x, names, rotation=0)\n",
    "#plt.xticks(votes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 4: Plotting from a pandas Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to visualize how far I've walked this week (using some random numbers).\n",
    "# Here's a dictionary that can be loaded as a pandas dataframe. Each item corresponds to a COLUMN.\n",
    "distance_walked = {'days': ['Monday','Tuesday','Wednesday','Thursday','Friday'],\n",
    "                   'km': [5,6,5,19,4]}\n",
    "\n",
    "# Turn it into a dataframe.\n",
    "df = pd.DataFrame.from_dict(distance_walked)\n",
    "\n",
    "# Plot the data using seaborn's built-in barplot function.\n",
    "# To select the color, I used the color chart from here: \n",
    "# http://stackoverflow.com/questions/22408237/named-colors-in-matplotlib\n",
    "ax = sns.barplot(x='days',y='km',color='lightsteelblue',data=df)\n",
    "\n",
    "# Here's a first customization. \n",
    "# Using the Matplotlib object returned by the plotting function, we can change the X- and Y-labels.\n",
    "ax.set_ylabel('km')\n",
    "ax.set_xlabel('')\n",
    "\n",
    "# Each matplotlib object consists of lines and patches that you can modify.\n",
    "# Each bar is a rectangle that you can access through the list of patches.\n",
    "# To make Thursday stand out even more, I changed its face color.\n",
    "ax.patches[3].set_facecolor('palevioletred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also plot a similar chart by directly using Pandas.\n",
    "ax = df.plot(x='days',y='km',kind='barh') # or kind='bar'\n",
    "\n",
    "# Remove the Y label and the legend.\n",
    "ax.set_ylabel('')\n",
    "ax.legend('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on bar/column plots:** while they're super useful, don't use them to visualize distributions. There was even a [Kickstarter](https://www.kickstarter.com/projects/1474588473/barbarplots) to raise money for sending T-shirts with a meme image to the editorial boards of big journals!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation\n",
    "\n",
    "Let's look at correlation between values in Python. We'll explore two measures: Pearson and Spearman correlation. Given two lists of numbers, Pearson looks whether there is any *linear relation* between those numbers. This is contrasted by the Spearman measure, which aims to see whether there is any *monotonic relation*. The difference between linear and monotonic is that the latter is typically less strict:\n",
    "\n",
    "* Monotonic: a constant relation between two lists of numbers.\n",
    "    1. if a number in one list increases, so does the number in the other list, or \n",
    "    2. if a number in one list increases, the number in the other list decreases.\n",
    "* Linear: similar to monotonic, but the increase or decrease can be modeled by a straight line.\n",
    "\n",
    "Here is a small example to illustrate the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scipy offers many statistical functions, among which the Pearson and Spearman correlation measures.\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "# X is equal to [1,2,3,...,99,100]\n",
    "x = list(range(100))\n",
    "\n",
    "# Y is equal to [1^2, 2^2, 3^2, ..., 99^2, 100^2]\n",
    "y = [i**2 for i in x]\n",
    "\n",
    "# Z is equal to [100,200,300, ..., 9900, 10000]\n",
    "z = [i*100 for i in x]\n",
    "\n",
    "# Plot x and y.\n",
    "plt.plot(x, y, label=\"X and Y\")\n",
    "\n",
    "# Plot y and z in the same plot.\n",
    "plt.plot(x, z, label=\"X and Z\")\n",
    "\n",
    "# Add a legend.\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation, significance = pearsonr(x,y)\n",
    "print('The Pearson correlation between X and Y is:', correlation)\n",
    "\n",
    "correlation, significance = spearmanr(x,y)\n",
    "print('The Spearman correlation between X and Y is:', correlation)\n",
    "\n",
    "print('----------------------------------------------------------')\n",
    "\n",
    "correlation, significance = pearsonr(x,z)\n",
    "print('The Pearson correlation between X and Z is:', correlation)\n",
    "\n",
    "correlation, significance = spearmanr(x,z)\n",
    "print('The Spearman correlation between X and Z is:', correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spearman correlation is perfect in both cases, because with each increase in X, there is an increase in Y. But because that increase isn't the same at each step, we see that the Pearson correlation is slightly lower.\n",
    "\n",
    "In Natural Language Processing, people typically use the Spearman correlation because they are interested in *relative scores*: does the model score A higher than B? The exact score often doesn't matter. Hence Spearman provides a better measure, because it doesn't penalize models for non-linear behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Putting it all together: Exploratory visualization and analysis\n",
    "\n",
    "Before you start working on a particular dataset, it's often a good idea to explore the data first. If you have text data; open the file and see what it looks like. If you have numeric data, it's a good idea to visualize what's going on. This section shows you some ways to do exactly that, on two datasets. \n",
    "\n",
    "### 4.1. A dataset with sentiment scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a histogram plot of sentiment scores for English (from [Dodds et al. 2014](http://www.uvm.edu/storylab/share/papers/dodds2014a/)), where native speakers rated a list of 10,022 words on a scale from 0 (negative) to 9 (positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data (one score per line, words are in a separate file).\n",
    "with open('../data/Dodds2014/data/labMTscores-english.csv') as f:\n",
    "    scores = [float(line.strip()) for line in f]\n",
    "\n",
    "# Plot the histogram\n",
    "sns.distplot(scores, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Dodds et al. collected data from several languages, we can plot the distributions for multiple languages and see whether they all have normally distributed scores. We will do this with a [Kernal Density Estimation](https://en.wikipedia.org/wiki/Kernel_density_estimation) plot. Basically, such a plot shows you the probability distribution (the chance of getting a particular score) as a continuous line. Because it's a line rather than a set of bars, you can show many of them in the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is necessary to get all the separate files.\n",
    "import glob\n",
    "\n",
    "# Get all the score files.\n",
    "filenames = glob.glob('../Data/Dodds2014/data/labMTscores-*.csv')\n",
    "\n",
    "# Showing the first 5, because else you can't keep track of all the lines.\n",
    "for filename in filenames[:5]:\n",
    "    # Read the language from the filename\n",
    "    language = filename.split('-')[1]\n",
    "    language = language.split('.')[0]\n",
    "    with open(filename) as f:\n",
    "        scores = [float(line.strip()) for line in f]\n",
    "        scores_array = np.array(scores) # This is necessary because the kdeplot function only accepts arrays.\n",
    "        sns.kdeplot(scores_array, label=language)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at all those unimodal distributions (with a single peak)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. A concreteness dataset\n",
    "\n",
    "We'll work with another data file by Brysbaert and colleagues, consisting of concreteness ratings. I.e. how abstract or concrete participants think a given word is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Let's load the data first.\n",
    "concreteness_entries = []\n",
    "with open('../data/Concreteness_ratings_Brysbaert_et_al_BRM.tsv') as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    for entry in reader:\n",
    "        entry['Conc.M'] = float(entry['Conc.M'])\n",
    "        concreteness_entries.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any kind of ratings, you can typically expect the data to have a normal-ish distribution: most of the data in the middle, and increasingly fewer scores on the extreme ends of the scale. We can check whether the data matches our expectation using a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for entry in concreteness_entries:\n",
    "    scores.append(entry['Conc.M'])\n",
    "\n",
    "# Plot the distribution of the scores.\n",
    "sns.distplot(scores, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "Surprise! It doesn't. This is a typical *bimodal* distribution with two peaks. Going back to [the original article](http://link.springer.com/sharelink/10.3758/s13428-013-0403-5), this is also mentioned in their discussion:\n",
    "\n",
    "> One concern, for instance, is that concreteness and abstractness may be not the two extremes of a quantitative continuum (reflecting the degree of sensory involvement, the degree to which words meanings are experience based, or the degree of contextual availability), but two qualitatively different characteristics. One argument for this view is that the distribution of concreteness ratings is bimodal, with separate peaks for concrete and abstract words, whereas ratings on a single, quantitative dimension usually are unimodal, with the majority of observations in the middle (Della Rosa et al., 2010; Ghio, Vaghi, & Tettamanti, 2013)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is commonly known in the literature on concreteness that concreteness ratings are (negatively) correlated with word length: the longer a word, the more abstract it typically is. Let's try to visualize this relation. We can plot the data using a regression plot to verify this. In addition, we're using a Pandas DataFrame to plot the data. You could also just use `sns.regplot(word_length, rating, x_jitter=0.4)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists of scores to correlate.\n",
    "word_length = []\n",
    "rating = []\n",
    "for entry in concreteness_entries:\n",
    "    word_length.append(len(entry['Word']))\n",
    "    rating.append(entry['Conc.M'])\n",
    "\n",
    "# Create a Pandas Dataframe. \n",
    "# I am using this here, because Seaborn adds text to the axes if you use DataFrames.\n",
    "# You could also use pd.read_csv(filename,delimiter='\\t') if you have a file ready to plot.\n",
    "df = pd.DataFrame.from_dict({\"Word length\": word_length, \"Rating\": rating})\n",
    "\n",
    "# Plot a regression line and (by default) the scatterplot. \n",
    "# We're adding some jitter because all the points fall on one line. \n",
    "# This makes it difficult to see how densely 'populated' the area is.\n",
    "# But with some random noise added to the scatterplot, you can see more clearly \n",
    "# where there are many dots and where there are fewer dots.\n",
    "sns.regplot('Word length', 'Rating', data=df, x_jitter=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't look like a super strong correlation. We can check by using the correlation measures from SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we're interested in predicting the actual rating.\n",
    "corr, sig = pearsonr(word_length, rating)\n",
    "print('Correlation, according to Pearsonr:', corr)\n",
    "\n",
    "# If we're interested in ranking the words by their concreteness.\n",
    "corr, sig = spearmanr(word_length, rating)\n",
    "print('Correlation, according to Spearmanr:', corr)\n",
    "\n",
    "# Because word length is bound to result in ties (many words have the same length), \n",
    "# some people argue you should use Kendall's Tau instead of Spearman's R:\n",
    "from scipy.stats import kendalltau\n",
    "\n",
    "corr, sig = kendalltau(word_length, rating)\n",
    "print(\"Correlation, according to Kendall's Tau:\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Take home message: The steps of visualization\n",
    "\n",
    "Now you've seen several different plots, hopefully the general pattern is becoming clear: visualization typically consists of three steps:\n",
    "\n",
    "1. Load the data.\n",
    "2. Organize the data in such a way that you can feed it to the visualization function.\n",
    "3. Plot the data using the function of your choice.\n",
    "\n",
    "There's also an optional **fourth step**: After plotting the data, tweak the plot until you're satisfied. Of these steps, the second and fourth are usually the most involved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Optional: On your own\n",
    "\n",
    "If you would like to practice, here is an exercise with data from Donald Trump's Facebook page. The relevant file is `Data/Trump-Facebook/FacebookStatuses.tsv`. Try to create a visualization that answers one of the following questions:\n",
    "\n",
    "1. How does the number of responses to Trump's posts change over time?\n",
    "2. What webpages does Donald Trump link to, and does this change over time? Which is the most popular? Are there any recent newcomers?\n",
    "3. What entities does Trump talk about?\n",
    "4. Starting March 2016 (when the emotional responses were introduced on Facebook), how have the emotional responses to Trumps messages developed?\n",
    "5. [Question of your own.]\n",
    "\n",
    "Try to at least think about what kind of visualization might be suitable to answer these questions, and we'll discuss this question in class on Monday. More specific questions:\n",
    "\n",
    "* What kind of preprocessing is necessary before you can start visualizing the data?\n",
    "* What kind of visualization is suitable for answering these questions?\n",
    "    - What sort of chart would you choose?\n",
    "    - How could you use color to improve your visualization?\n",
    "* What might be difficult about visualizing this data? How could you overcome those difficulties?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data.\n",
    "\n",
    "\n",
    "# Process the data so that it can be visualized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data.\n",
    "\n",
    "\n",
    "# Modify the plot.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
